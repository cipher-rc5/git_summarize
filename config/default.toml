# Git Summarize RAG Pipeline Configuration

[repository]
# GitHub repository URL (public or private with credentials)
# Example: "https://github.com/username/repo"
# For private repos with token: "https://TOKEN@github.com/username/repo"
source_url = "https://github.com/user/example-repo"

# Local path where repository will be cloned
local_path = "./data_repo"

# Branch to track
branch = "main"

# Enable automatic sync on start
sync_on_start = true

[database]
# LanceDB storage URI
# Can be a local path or remote URI
uri = "data/lancedb"

# Table name for document storage
table_name = "documents"

# Batch size for bulk insertions
batch_size = 100

# Groq API configuration (optional)
# groq_api_key = "your-groq-api-key-here"  # Or use env var GROQ_API_KEY
groq_model = "openai/gpt-oss-120b"

[pipeline]
# Number of parallel workers for processing files
parallel_workers = 4

# Patterns to skip during scanning
skip_patterns = [
  "*.zip",
  "*.pdf",
  "*.exe",
  "*.dll",
  "*.bin",
  ".git/*",
  "node_modules/*",
  "target/*",
  "dist/*",
  "build/*",
]

# Force reprocess all files (ignores cache)
force_reprocess = false

# Maximum file size in megabytes
max_file_size_mb = 10

[extraction]
# Normalize markdown before extraction
normalize_markdown = true

# Custom categories for classifying files based on path keywords
# Each category can have multiple keywords that trigger its classification
# Example configurations for different types of projects:

# For a web application project:
# [[extraction.categories]]
# keywords = ["frontend", "ui", "components", "views"]
# category = "frontend"
#
# [[extraction.categories]]
# keywords = ["backend", "api", "server", "services"]
# category = "backend"
#
# [[extraction.categories]]
# keywords = ["tests", "spec", "__tests__", "test"]
# category = "testing"

# For a data science project:
# [[extraction.categories]]
# keywords = ["notebooks", "analysis", "exploration"]
# category = "analysis"
#
# [[extraction.categories]]
# keywords = ["models", "training", "ml"]
# category = "machine_learning"

# Custom topics for identifying specific subjects in file paths
# Topics are more granular than categories

# For a web application:
# [[extraction.topics]]
# keyword = "authentication"
# topic = "auth"
#
# [[extraction.topics]]
# keyword = "database"
# topic = "data_layer"
#
# [[extraction.topics]]
# keyword = "payment"
# topic = "billing"

# For documentation:
# [[extraction.topics]]
# keyword = "tutorial"
# topic = "learning"
#
# [[extraction.topics]]
# keyword = "api"
# topic = "api_reference"
